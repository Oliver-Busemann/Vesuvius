{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad93d493",
   "metadata": {},
   "source": [
    "# Notebook to build the CV-Setup on which to improve on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import timm\n",
    "from torchinfo import summary\n",
    "from copy import deepcopy\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c14d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/olli/Projects/Kaggle/Vesuvius'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54ddce",
   "metadata": {},
   "source": [
    "# There are 3 scans so a 3-fold-Cross-Validation makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcda732",
   "metadata": {},
   "source": [
    "## For this first create each fold (each fold is one scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1_path = os.path.join(folder, 'train/1')\n",
    "fold_2_path = os.path.join(folder, 'train/2')\n",
    "fold_3_path = os.path.join(folder, 'train/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_1 = glob(fold_1_path + '/surface_volume/*.tif')\n",
    "scans_2 = glob(fold_2_path + '/surface_volume/*.tif')\n",
    "scans_3 = glob(fold_3_path + '/surface_volume/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b723960",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_1.sort()\n",
    "scans_2.sort()\n",
    "scans_3.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18508fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [scans_1, scans_2, scans_3]:\n",
    "    print(i[0], '\\n', i[-1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49921d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [scans_1, scans_2, scans_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53adb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_paths = [fold_1_path, fold_2_path, fold_3_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344c2a0",
   "metadata": {},
   "source": [
    "## Now create a generic dataset for the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Dataset-class takes as input the folder of a scan as well as all paths to the volumes (sorted).\n",
    "   Each scan is returned as a 3D-volume as well as the label.\n",
    "   The volume is normalized, however this can not be in one part.\n",
    "   The reason is a limit in RAM: One scan takes ~16GB of RAM and normalizing the full volume crashed the kernel.\n",
    "    -> Needs more then 33.6GB of available RAM.\n",
    "   Thats why the normalization is done in slices: Each scan layer will be normalized to a fix mean & std.\n",
    "    -> This doesn't take much additional RAM.\n",
    "   The depth means how many layers to load (max: 65)\n",
    "'''\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, path, scans_paths, depth=10):\n",
    "        \n",
    "        self.scans = scans_paths\n",
    "        self.paths = path\n",
    "        self.depth = depth\n",
    "        assert self.depth > 1 and self.depth <= 65\n",
    "        \n",
    "    def __len__(self):  # number of scans for this dataset\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # load the label for the scan\n",
    "        label_path = os.path.join(self.paths[index], 'inklabels.png')\n",
    "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # no colors\n",
    "        \n",
    "        # create an empty volume and assign each scan layer; get the shape from the label (same as scan for h x w)\n",
    "        height, width = label.shape\n",
    "        scan = torch.empty(65, height, width)\n",
    "        \n",
    "        # now assign each layer at the correct dim\n",
    "        for i in range(self.depth):  # 0...64\n",
    "            scan_array = cv2.imread(folds[index][i], cv2.IMREAD_GRAYSCALE)\n",
    "            scan[i, :, :] = torch.tensor(scan_array)\n",
    "            scan[i, :, :] = scan[i, :, :].type(torch.float32)\n",
    "            scan[i, :, :] = scan[i, :, :] / 255.0\n",
    "            \n",
    "            #normalize each slize on its own to a mean of 0.5 and a std of 0.5!\n",
    "            scan[i, :, :] = (scan[i, :, :] - scan[i, :, :].mean()) / (scan[i, :, :].std() * 2.) + 0.5\n",
    "            \n",
    "            \n",
    "        return scan, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write a function that returns the different train/valid-datasets and -paths.\n",
    "   Each fold once is the validation data, the rest is for training.'''\n",
    "\n",
    "\n",
    "def create_train_valid():\n",
    "\n",
    "    train_folds = ['tr_1', 'tr_2', 'tr_3']\n",
    "    valid_folds = ['val_1', 'val_2', 'val_3']\n",
    "    train_paths = ['tr_path_1', 'tr_path_2', 'tr_path_3']\n",
    "    valid_paths = ['val_path_1', 'val_path_2', 'val_path_3']\n",
    "\n",
    "    # assign each train/valid dataset the correct folds with i\n",
    "    for i, train, valid in zip(range(3), train_folds, valid_folds):\n",
    "\n",
    "        paths = deepcopy(fold_paths)\n",
    "        flds = deepcopy(folds)\n",
    "\n",
    "        globals()[valid_paths[i]] = [paths.pop(i)]  # i'ths index is valid rest is for train\n",
    "        globals()[train_paths[i]] = paths\n",
    "\n",
    "        globals()[valid_folds[i]] = [flds.pop(i)]\n",
    "        globals()[train_folds[i]] = flds\n",
    "        \n",
    "    train_folds = [tr_1, tr_2, tr_3]\n",
    "    valid_folds = [val_1, val_2, val_3]\n",
    "    \n",
    "    train_paths = [tr_path_1, tr_path_2, tr_path_3]\n",
    "    valid_paths = [val_path_1, val_path_2, val_path_3]\n",
    "    \n",
    "    return train_folds, valid_folds, train_paths, valid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94bb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds, valid_folds, train_paths, valid_paths = create_train_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608403d1",
   "metadata": {},
   "source": [
    "### Check if it worked to see each train-/valid-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd65dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tr, val in zip(range(3), train_paths, valid_paths):\n",
    "    print(f'Dataset {i}: Train-Path: {tr}; Valid_Path: {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d2a39",
   "metadata": {},
   "source": [
    "### Each valid fold is excluded for train so it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f697e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    train_path = train_paths[i]\n",
    "    valid_path = valid_paths[i]\n",
    "    \n",
    "    train_data = train_folds[i]\n",
    "    valid_data = valid_folds[i]\n",
    "    \n",
    "    tr_ds = Data(path=train_path, scans_paths=train_data)\n",
    "    val_ds = Data(path=valid_path, scans_paths=valid_data)\n",
    "    \n",
    "    print(f'Dataset {i + 1}: Train-samples: {tr_ds.__len__()}; Valid-samples: {val_ds.__len__()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113504b",
   "metadata": {},
   "source": [
    "# Now build a simple 2D Conv Net that predicts each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name='se_resnext50_32x4d',        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d1af7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(model, input_data=torch.randn(1, 1, 6336, 8192).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2534e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
